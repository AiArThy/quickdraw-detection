{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quickdraw_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOqRw5cRyUqenn25ZCVh/9x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AiArThy/quickdraw-detection-model/blob/object-detection/quickdraw_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeoUkYCpQcHA",
        "outputId": "ffd502d5-d1be-451f-af11-8cc5320c48b4"
      },
      "source": [
        "!pip install --quiet tensorflow==1.15\r\n",
        "!pip install --quiet tensorflow_gpu==1.15"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 412.3MB 38kB/s \n",
            "\u001b[K     |████████████████████████████████| 512kB 55.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 50.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n",
            "\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 40kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6XNG0VQQhxq",
        "outputId": "82e17880-ccc3-489b-bef7-e882872abcfb"
      },
      "source": [
        "import os\r\n",
        "from google.colab import drive\r\n",
        "\r\n",
        "if not os.path.exists('/content/gdrive'):\r\n",
        "  drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqaV9nqDQjMf",
        "outputId": "dea7b753-9dd2-4dcf-d07b-f38f2b80c8b1"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/quickdraw_train"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/quickdraw_train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2LmBJADQkjZ",
        "outputId": "4abba2ac-c138-4a4d-ab81-4f26ea5364eb"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "\r\n",
        "repo_url = 'https://github.com/zihenglin/quick-draw-recognition'\r\n",
        "\r\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\r\n",
        "\r\n",
        "\r\n",
        "!git clone {repo_url}\r\n",
        "%cd {repo_dir_path}\r\n",
        "!git pull\r\n",
        "\r\n",
        "%cd .."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'quick-draw-recognition'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Total 19 (delta 0), reused 0 (delta 0), pack-reused 19\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n",
            "/content/gdrive/MyDrive/quickdraw_train/quick-draw-recognition\n",
            "Already up to date.\n",
            "/content/gdrive/My Drive/quickdraw_train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M38bVNS3Qncc",
        "outputId": "992f0d91-6010-41a4-af4f-53b628b2edfa"
      },
      "source": [
        "!git clone --quiet https://github.com/tensorflow/models.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 160975 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.4_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.4) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.4) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "\u001b[K     |████████████████████████████████| 358kB 4.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7fEWuxQvq-k",
        "outputId": "3eae1672-b313-4361-f1f2-0d733a19f630"
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\r\n",
        "\r\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib pycocotools tf_slim"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 160975 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.4_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.4) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.4) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "\u001b[K     |████████████████████████████████| 358kB 10.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyZNsAqCQsHX",
        "outputId": "5ddd71b8-a4b8-4039-9b87-ee2b335cc78e"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/quickdraw_train/models/research\r\n",
        "!protoc object_detection/protos/*.proto --python_out=.\r\n",
        "\r\n",
        "import os\r\n",
        "os.environ['PYTHONPATH'] += ':/content/gdrive/MyDrive/quickdraw_train/models/research/:/content/gdrive/MyDrive/quickdraw_train/models/research/slim/'\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/quickdraw_train/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph0n-9ClQvEN"
      },
      "source": [
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yefQNC7TQytO",
        "outputId": "8f8d654d-f785-40d5-d563-d562a1dd07e3"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/quickdraw_train"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/quickdraw_train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkGIgbTvSF9h"
      },
      "source": [
        "%mkdir training"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4llYKvuYSIk0",
        "outputId": "09286cbe-b0ab-438e-fc90-4e17d6da56c6"
      },
      "source": [
        "%cd training"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/quickdraw_train/training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGpN4jc_SKN6"
      },
      "source": [
        "%mkdir sample\r\n",
        "%mkdir annotation\r\n",
        "%mkdir combined_image\r\n",
        "%mkdir saved_model\r\n",
        "%mkdir tfrecord\r\n",
        "%mkdir model_ckpt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxjSemJwS4W_",
        "outputId": "a19bd31b-cc80-4bc5-8fcf-9d9b3e733968"
      },
      "source": [
        "%cd sample"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/quickdraw_train/training/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYSqef8sTAIe",
        "outputId": "f5e6925b-734e-4789-a8ec-d72718eb85b0"
      },
      "source": [
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/raw/house.ndjson\r\n",
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/raw/face.ndjson\r\n",
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/raw/tree.ndjson"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-11 17:19:10--  https://storage.googleapis.com/quickdraw_dataset/full/raw/house.ndjson\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.218.128, 64.233.170.128, 108.177.12.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.218.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 437886394 (418M) [application/octet-stream]\n",
            "Saving to: ‘house.ndjson’\n",
            "\n",
            "house.ndjson        100%[===================>] 417.60M  35.8MB/s    in 12s     \n",
            "\n",
            "2021-03-11 17:19:21 (36.1 MB/s) - ‘house.ndjson’ saved [437886394/437886394]\n",
            "\n",
            "--2021-03-11 17:19:22--  https://storage.googleapis.com/quickdraw_dataset/full/raw/face.ndjson\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.218.128, 64.233.170.128, 108.177.12.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.218.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593069574 (566M) [application/octet-stream]\n",
            "Saving to: ‘face.ndjson’\n",
            "\n",
            "face.ndjson         100%[===================>] 565.59M  39.1MB/s    in 16s     \n",
            "\n",
            "2021-03-11 17:19:38 (34.4 MB/s) - ‘face.ndjson’ saved [593069574/593069574]\n",
            "\n",
            "--2021-03-11 17:19:38--  https://storage.googleapis.com/quickdraw_dataset/full/raw/tree.ndjson\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.26.128, 172.217.193.128, 172.217.204.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.26.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 575014577 (548M) [application/octet-stream]\n",
            "Saving to: ‘tree.ndjson’\n",
            "\n",
            "tree.ndjson         100%[===================>] 548.38M  33.4MB/s    in 15s     \n",
            "\n",
            "2021-03-11 17:19:54 (36.0 MB/s) - ‘tree.ndjson’ saved [575014577/575014577]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TXjXmIJTKh0",
        "outputId": "ce1b6b45-8b21-4f14-b42a-34551abfbd99"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/quickdraw_train/training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4Okzyv7TiBJ"
      },
      "source": [
        "%mv /content/gdrive/MyDrive/quickdraw_train/quick-draw-recognition/scripts/combine_quick_drawings.py ./\r\n",
        "%mv /content/gdrive/MyDrive/quickdraw_train/quick-draw-recognition/scripts/convert_ndjson_to_png.py ./\r\n",
        "%mv /content/gdrive/MyDrive/quickdraw_train/quick-draw-recognition/scripts/create_tfrecord.py ./\r\n",
        "%mv /content/gdrive/MyDrive/quickdraw_train/quick-draw-recognition/scripts/export_frozen_graph.sh ./\r\n",
        "%mv /content/gdrive/MyDrive/quickdraw_train/quick-draw-recognition/scripts/train_faster_rcnn_inception_v2.sh ./"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8_ELk5SUg8V"
      },
      "source": [
        "%mv /content/gdrive/MyDrive/quickdraw_train/quick-draw-recognition/code ./"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PvV3bHzT-vW"
      },
      "source": [
        "# **convert_ndjson_to_png.py**\r\n",
        "\r\n",
        "OBJECT_LIST = ['house', 'face', 'tree']  <br>\r\n",
        "\r\n",
        "\r\n",
        "IMAGE_BASE_DIR='./sample' "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAS_VSY9T3A0",
        "outputId": "cb82ac80-813a-4985-b173-a5d2947fa074"
      },
      "source": [
        "!python convert_ndjson_to_png.py --object_limit=1000 --n_processes=1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Working on object class house.\n",
            "INFO:root:Working on object class face.\n",
            "INFO:root:Working on object class tree.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj9tVZVqU8dy"
      },
      "source": [
        "# **combine_quick_drawings.py**\r\n",
        "\r\n",
        "OBJECT_LIST = ['house', 'face', 'tree']  <br>\r\n",
        "\r\n",
        "IMAGE_BASE_DIR = './sample' <br>\r\n",
        "OUTPUT_ANNOTATION_DIR = './annotation' <br>\r\n",
        "OUTPUT_IMAGE_DIR = './combined_image' <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGJqhulXUuHg"
      },
      "source": [
        "!python combine_quick_drawings.py --total_images=100000 "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLUxkW4nW4zG"
      },
      "source": [
        "# **create_tfrecord.py**\r\n",
        "\r\n",
        "text_to_int_map = {'house': 1, 'face': 2, 'tree': 3}  <br>\r\n",
        "\r\n",
        "COMBINED_IMAGE_PATH = './combined_image'  <br>\r\n",
        "ANNOTATION_FILE_PATH = './annotation/annotation.csv'  <br>\r\n",
        "TF_RECORD_OUTPUT_FILE_PATH = './tfrecord/train.record'  <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pwfU5K7WfsI",
        "outputId": "5df74005-13fd-4c01-b0ef-0d88ec3a0b68"
      },
      "source": [
        "!python create_tfrecord.py\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From create_tfrecord.py:97: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From create_tfrecord.py:40: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OffjAIuZoIR"
      },
      "source": [
        "%mv /content/gdrive/MyDrive/quickdraw_train/quick-draw-recognition/config ./"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX-n-nLEZAE-"
      },
      "source": [
        "# **train_faster_rcnn_inception_v2.sh**\r\n",
        "\r\n",
        "text_to_int_map = {'house': 1, 'face': 2, 'tree': 3}  <br>\r\n",
        "\r\n",
        "COMBINED_IMAGE_PATH = './combined_image'  <br>\r\n",
        "ANNOTATION_FILE_PATH = './annotation/annotation.csv'  <br>\r\n",
        "TF_RECORD_OUTPUT_FILE_PATH = './tfrecord/train.record'  <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYPrngZuaMPG"
      },
      "source": [
        "# **faster_rcnn_inception_v2.config**\r\n",
        "\r\n",
        "num_classes: 3  <br>\r\n",
        "\r\n",
        "input_path: \"/content/gdrive/MyDrive/quickdraw_train/training/tfrecord/train.record\"  <br>\r\n",
        "label_map_path: \"/content/gdrive/MyDrive/quickdraw_train/training/label_map.pbtxt\"  <br>\r\n",
        "max_detections_per_class: 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2hjPYUcbksO"
      },
      "source": [
        "# **label_map.pbtxt**\r\n",
        "\r\n",
        "item {\r\n",
        "  id: 1\r\n",
        "  name: 'house'\r\n",
        "}\r\n",
        "\r\n",
        "item {\r\n",
        "  id: 2\r\n",
        "  name: 'face'\r\n",
        "}\r\n",
        "\r\n",
        "item {\r\n",
        "  id: 3\r\n",
        "  name: 'tree'\r\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iyAH_bIY3h0",
        "outputId": "e4ee6be7-38f9-4fc5-c161-32948a728495"
      },
      "source": [
        "!sh train_faster_rcnn_inception_v2.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/absl/app.py:251: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "W0311 18:59:59.275835 140269439207296 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/absl/app.py:251: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/legacy/trainer.py:265: create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "W0311 18:59:59.293870 140269439207296 deprecation.py:323] From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/legacy/trainer.py:265: create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/gdrive/MyDrive/quickdraw_train/training/tfrecord/train.record']\n",
            "I0311 18:59:59.321825 140269439207296 dataset_builder.py:163] Reading unweighted datasets: ['/content/gdrive/MyDrive/quickdraw_train/training/tfrecord/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/gdrive/MyDrive/quickdraw_train/training/tfrecord/train.record']\n",
            "I0311 18:59:59.323664 140269439207296 dataset_builder.py:80] Reading record datasets for input file: ['/content/gdrive/MyDrive/quickdraw_train/training/tfrecord/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0311 18:59:59.323853 140269439207296 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0311 18:59:59.323993 140269439207296 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0311 18:59:59.330612 140269439207296 deprecation.py:323] From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0311 18:59:59.352768 140269439207296 deprecation.py:323] From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/builders/dataset_builder.py:49: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "W0311 19:00:02.403400 140269439207296 deprecation.py:323] From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/builders/dataset_builder.py:49: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "W0311 19:00:02.455412 140269439207296 deprecation.py:323] From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0311 19:00:02.459989 140269439207296 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0311 19:00:02.461218 140269439207296 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0311 19:00:03.189331 140269439207296 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0311 19:00:04.914944 140269439207296 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0311 19:00:05.070323 140269439207296 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0311 19:00:05.070789 140269439207296 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/core/box_list_ops.py:202: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0311 19:00:05.121300 140269439207296 deprecation.py:323] From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/core/box_list_ops.py:202: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0311 19:00:13.521757 140269439207296 deprecation.py:506] From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0311 19:00:14.187772 140269439207296 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0311 19:00:14.190775 140269439207296 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0311 19:00:14.211346 140269439207296 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/core/losses.py:453: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0311 19:00:17.305162 140269439207296 deprecation.py:323] From /content/gdrive/MyDrive/quickdraw_train/models/research/object_detection/core/losses.py:453: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0311 19:00:26.389381 140269439207296 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0311 19:00:28.603516 140269439207296 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/learning.py:734: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "W0311 19:00:35.410782 140269439207296 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/learning.py:734: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "2021-03-11 19:00:37.345157: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-03-11 19:00:37.350455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-03-11 19:00:37.350698: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c0b2fb80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-11 19:00:37.350734: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-03-11 19:00:37.353034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-11 19:00:37.364002: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-03-11 19:00:37.364051: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (79b66d47e5da): /proc/driver/nvidia/version does not exist\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0311 19:00:43.020555 140269439207296 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0311 19:00:43.863875 140269439207296 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Starting Session.\n",
            "I0311 19:00:59.674432 140269439207296 learning.py:746] Starting Session.\n",
            "INFO:tensorflow:Saving checkpoint to path /content/gdrive/MyDrive/quickdraw_train/training/model_ckpt/model.ckpt\n",
            "I0311 19:01:00.398804 140267078039296 supervisor.py:1117] Saving checkpoint to path /content/gdrive/MyDrive/quickdraw_train/training/model_ckpt/model.ckpt\n",
            "INFO:tensorflow:Starting Queues.\n",
            "I0311 19:01:00.404032 140269439207296 learning.py:760] Starting Queues.\n",
            "INFO:tensorflow:global_step/sec: 0\n",
            "I0311 19:01:27.013919 140267086432000 supervisor.py:1099] global_step/sec: 0\n",
            "2021-03-11 19:01:29.800755: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 192000000 exceeds 10% of system memory.\n",
            "2021-03-11 19:01:30.851609: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 192000000 exceeds 10% of system memory.\n",
            "2021-03-11 19:01:31.321233: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 192000000 exceeds 10% of system memory.\n",
            "2021-03-11 19:01:31.387415: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 144000000 exceeds 10% of system memory.\n",
            "2021-03-11 19:01:32.324239: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 144000000 exceeds 10% of system memory.\n",
            "INFO:tensorflow:Recording summary at step 0.\n",
            "I0311 19:01:48.271209 140267094824704 supervisor.py:1050] Recording summary at step 0.\n",
            "INFO:tensorflow:global step 1: loss = 6.6397 (80.322 sec/step)\n",
            "I0311 19:02:21.511851 140269439207296 learning.py:512] global step 1: loss = 6.6397 (80.322 sec/step)\n",
            "INFO:tensorflow:global step 2: loss = 4.7645 (40.421 sec/step)\n",
            "I0311 19:03:02.727050 140269439207296 learning.py:512] global step 2: loss = 4.7645 (40.421 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 2.\n",
            "I0311 19:03:19.760169 140267094824704 supervisor.py:1050] Recording summary at step 2.\n",
            "INFO:tensorflow:global_step/sec: 0.0177353\n",
            "I0311 19:03:19.783033 140267086432000 supervisor.py:1099] global_step/sec: 0.0177353\n",
            "INFO:tensorflow:global step 3: loss = 2.9784 (47.850 sec/step)\n",
            "I0311 19:03:50.579378 140269439207296 learning.py:512] global step 3: loss = 2.9784 (47.850 sec/step)\n",
            "INFO:tensorflow:global step 4: loss = 2.5313 (39.630 sec/step)\n",
            "I0311 19:04:30.210615 140269439207296 learning.py:512] global step 4: loss = 2.5313 (39.630 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 0.0169363\n",
            "I0311 19:05:17.872610 140267086432000 supervisor.py:1099] global_step/sec: 0.0169363\n",
            "INFO:tensorflow:Recording summary at step 4.\n",
            "I0311 19:05:17.873102 140267094824704 supervisor.py:1050] Recording summary at step 4.\n",
            "INFO:tensorflow:global step 5: loss = 2.4729 (48.772 sec/step)\n",
            "I0311 19:05:18.983637 140269439207296 learning.py:512] global step 5: loss = 2.4729 (48.772 sec/step)\n",
            "INFO:tensorflow:global step 6: loss = 2.1319 (39.718 sec/step)\n",
            "I0311 19:05:58.703132 140269439207296 learning.py:512] global step 6: loss = 2.1319 (39.718 sec/step)\n",
            "INFO:tensorflow:global step 7: loss = 1.8273 (40.394 sec/step)\n",
            "I0311 19:06:39.098479 140269439207296 learning.py:512] global step 7: loss = 1.8273 (40.394 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 7.\n",
            "I0311 19:07:17.654795 140267094824704 supervisor.py:1050] Recording summary at step 7.\n",
            "INFO:tensorflow:global_step/sec: 0.0250219\n",
            "I0311 19:07:17.767736 140267086432000 supervisor.py:1099] global_step/sec: 0.0250219\n",
            "INFO:tensorflow:global step 8: loss = 1.4884 (49.389 sec/step)\n",
            "I0311 19:07:28.488693 140269439207296 learning.py:512] global step 8: loss = 1.4884 (49.389 sec/step)\n",
            "INFO:tensorflow:global step 9: loss = 1.3504 (40.051 sec/step)\n",
            "I0311 19:08:08.541137 140269439207296 learning.py:512] global step 9: loss = 1.3504 (40.051 sec/step)\n",
            "INFO:tensorflow:global step 10: loss = 1.4370 (39.710 sec/step)\n",
            "I0311 19:08:48.252594 140269439207296 learning.py:512] global step 10: loss = 1.4370 (39.710 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 10.\n",
            "I0311 19:09:17.146560 140267094824704 supervisor.py:1050] Recording summary at step 10.\n",
            "INFO:tensorflow:global_step/sec: 0.0251218\n",
            "I0311 19:09:17.186037 140267086432000 supervisor.py:1099] global_step/sec: 0.0251218\n",
            "INFO:tensorflow:global step 11: loss = 1.4142 (48.889 sec/step)\n",
            "I0311 19:09:37.142671 140269439207296 learning.py:512] global step 11: loss = 1.4142 (48.889 sec/step)\n",
            "INFO:tensorflow:global step 12: loss = 1.3997 (41.025 sec/step)\n",
            "I0311 19:10:18.168909 140269439207296 learning.py:512] global step 12: loss = 1.3997 (41.025 sec/step)\n",
            "INFO:tensorflow:global step 13: loss = 1.3598 (40.217 sec/step)\n",
            "I0311 19:10:58.386827 140269439207296 learning.py:512] global step 13: loss = 1.3598 (40.217 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/gdrive/MyDrive/quickdraw_train/training/model_ckpt/model.ckpt\n",
            "I0311 19:11:00.399647 140267078039296 supervisor.py:1117] Saving checkpoint to path /content/gdrive/MyDrive/quickdraw_train/training/model_ckpt/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 13.\n",
            "I0311 19:11:18.191224 140267094824704 supervisor.py:1050] Recording summary at step 13.\n",
            "INFO:tensorflow:global_step/sec: 0.024784\n",
            "I0311 19:11:18.231638 140267086432000 supervisor.py:1099] global_step/sec: 0.024784\n",
            "INFO:tensorflow:global step 14: loss = 1.3332 (52.060 sec/step)\n",
            "I0311 19:11:50.448071 140269439207296 learning.py:512] global step 14: loss = 1.3332 (52.060 sec/step)\n",
            "INFO:tensorflow:global step 15: loss = 1.3824 (40.392 sec/step)\n",
            "I0311 19:12:30.841373 140269439207296 learning.py:512] global step 15: loss = 1.3824 (40.392 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 15.\n",
            "I0311 19:13:18.101962 140267094824704 supervisor.py:1050] Recording summary at step 15.\n",
            "INFO:tensorflow:global_step/sec: 0.0166743\n",
            "I0311 19:13:18.177120 140267086432000 supervisor.py:1099] global_step/sec: 0.0166743\n",
            "INFO:tensorflow:global step 16: loss = 1.2556 (49.346 sec/step)\n",
            "I0311 19:13:20.188954 140269439207296 learning.py:512] global step 16: loss = 1.2556 (49.346 sec/step)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOReuyz6qP99"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/quickdraw_train/models/research/slim\r\n",
        "\r\n",
        "!python setup.py build\r\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZBqm4XFsQKm"
      },
      "source": [
        "# **exporter.py 수정 -> exporter_savedmodel.py**\r\n",
        "\r\n",
        "Object Detection API가 저장되어 있는 <br>\r\n",
        "/content/gdrive/MyDrive/quickdraw_train/models/research/object_detection 에 파일을 업로드합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QDGca23snvt"
      },
      "source": [
        ">Line 72: <br>\r\n",
        "change optimize_tensor_layout=True ==>  layout_optimizer=True  <br>\r\n",
        "\r\n",
        "> Line 327-329:<p>\r\n",
        "preprocessed_inputs, true_image_shapes = detection_model.preprocess(inputs)<p>\r\n",
        "output_tensors = detection_model.predict(preprocessed_inputs, true_image_shapes)<p>\r\n",
        "postprocessed_tensors = detection_model.postprocess(output_tensors, true_image_shapes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt0YdiTIrIF9"
      },
      "source": [
        "!saved_model_cli show --dir '/content/gdrive/MyDrive/quickdraw_train/training/saved_model/1' --all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIY44qkBngL8"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "from object_detection.utils.config_util import create_pipeline_proto_from_configs\r\n",
        "from object_detection.utils.config_util import get_configs_from_pipeline_file\r\n",
        "import object_detection.exporter_savedmodel\r\n",
        "\r\n",
        "# export하는 학습 모델의 Configuration 파일 경로\r\n",
        "config_pathname = '/content/gdrive/MyDrive/quickdraw_train/training/config/faster_rcnn_inception_v2.config'\r\n",
        "\r\n",
        "# export하는 학습 모델의 checkpoint 경로\r\n",
        "trained_model_dir = '/content/gdrive/MyDrive/quickdraw_train/training/model_ckpt' \r\n",
        "\r\n",
        "# Configuration 파일에서 proto를 생성\r\n",
        "configs = get_configs_from_pipeline_file(config_pathname)\r\n",
        "pipeline_proto = create_pipeline_proto_from_configs(configs=configs)\r\n",
        "\r\n",
        "# model checkpoint 경로에서 .ckpt와 .meta 파일을 읽기\r\n",
        "checkpoint = tf.train.get_checkpoint_state(trained_model_dir)\r\n",
        "input_checkpoint = checkpoint.model_checkpoint_path\r\n",
        "\r\n",
        "# 모델 버전\r\n",
        "model_version_id = 1\r\n",
        "\r\n",
        "# Output 디렉토리 경로\r\n",
        "output_directory = '/content/gdrive/MyDrive/quickdraw_train/training/saved_model' + '/' + str(model_version_id)\r\n",
        "\r\n",
        "# 모델 export 하기\r\n",
        "object_detection.exporter_savedmodel.export_inference_graph(input_type='image_tensor', pipeline_config=pipeline_proto, trained_checkpoint_prefix=input_checkpoint, output_directory=output_directory)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRxbNRfgq5pF"
      },
      "source": [
        "1. input_type='image_tensor'로 하면 image tensor를 json serializion 합니다.\r\n",
        "\r\n",
        "2. input_type='encoded_image_string_tensor'로 하면 base64를 json serializion 합니다.\r\n",
        "\r\n",
        "3. input_type='tf_example'로 하면 tf example를 json serializtion 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuWasjASr_xO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}