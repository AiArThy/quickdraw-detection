{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quickdraw_test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5QXVV40TbCzeYY2IQCOhI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AiArThy/quickdraw-detection-model/blob/object-detection/quickdraw_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-qcTlU40_rx"
      },
      "source": [
        "import os\r\n",
        "from google.colab import drive\r\n",
        "\r\n",
        "if not os.path.exists('/content/gdrive'):\r\n",
        "  drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4cX2Ul_2mMB"
      },
      "source": [
        "tf.__version__  # 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt6XwjeQ1ITk"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/quickdraw_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtYzsZhB1Qzn"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from object_detection.utils import ops as utils_ops\r\n",
        "from object_detection.utils import label_map_util\r\n",
        "from object_detection.utils import visualization_utils as vis_util\r\n",
        "import numpy as np\r\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g2YFh2P1T2C"
      },
      "source": [
        "model = tf.saved_model.load(str('/content/gdrive/MyDrive/quickdraw_train/training/saved_model/1'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYFoypYD1f0o"
      },
      "source": [
        "import os\r\n",
        "os.environ['PYTHONPATH'] += ':/content/gdrive/MyDrive/quickdraw_train/models/research/:/content/gdrive/MyDrive/quickdraw_train/models/research/slim/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sYK1xFV1nHq"
      },
      "source": [
        "print(model.signatures['serving_default'].inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fcQy18X1qx1"
      },
      "source": [
        "model.signatures['serving_default'].output_shapes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFOypJ8O1s4-"
      },
      "source": [
        "model.signatures['serving_default'].output_dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBE5RvzC1uml"
      },
      "source": [
        "def run_inference_for_single_image(model, image):\r\n",
        "  image = np.asarray(image)\r\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\r\n",
        "  input_tensor = tf.convert_to_tensor(image)\r\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\r\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\r\n",
        "\r\n",
        "  # Run inference\r\n",
        "  model_fn = model.signatures['serving_default']\r\n",
        "  output_dict = model_fn(input_tensor)\r\n",
        "\r\n",
        "  # All outputs are batches tensors.\r\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\r\n",
        "  # We're only interested in the first num_detections.\r\n",
        "  num_detections = int(output_dict.pop('num_detections'))\r\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \r\n",
        "                 for key,value in output_dict.items()}\r\n",
        "  output_dict['num_detections'] = num_detections\r\n",
        "\r\n",
        "  # detection_classes should be ints.\r\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\r\n",
        "   \r\n",
        "  # Handle models with masks:\r\n",
        "  if 'detection_masks' in output_dict:\r\n",
        "    # Reframe the the bbox mask to the image size.\r\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\r\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\r\n",
        "               image.shape[0], image.shape[1])      \r\n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\r\n",
        "                                       tf.uint8)\r\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\r\n",
        "  print(output_dict)\r\n",
        "  return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJWbPf0z1vMo"
      },
      "source": [
        "def show_inference(model, image_path):\r\n",
        "  # the array based representation of the image will be used later in order to prepare the\r\n",
        "  # result image with boxes and labels on it.\r\n",
        "  image_np = np.array(Image.open(image_path))\r\n",
        "  # image_np = np.dstack([image_np]*3) <- if gray (channel 1) image\r\n",
        "  # Actual detection.\r\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\r\n",
        "  # Visualization of the results of a detection.\r\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\r\n",
        "      image_np,\r\n",
        "      output_dict['detection_boxes'],\r\n",
        "      output_dict['detection_classes'],\r\n",
        "      output_dict['detection_scores'],\r\n",
        "      category_index,\r\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\r\n",
        "      use_normalized_coordinates=True,\r\n",
        "      line_thickness=8)\r\n",
        "\r\n",
        "  display(Image.fromarray(image_np))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTV95OXG13BW"
      },
      "source": [
        "PATH_TO_LABELS = '/content/gdrive/MyDrive/tf/quick-draw-recognition/label_map.pbtxt'\r\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ml_KU3C2CI2"
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\r\n",
        "\r\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib pycocotools tf_slim\r\n",
        "\r\n",
        "%cd /content/gdrive/MyDrive/quickdraw_train/models/research\r\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BKS6Kge2QYw"
      },
      "source": [
        "show_inference(model, '/content/htp.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}